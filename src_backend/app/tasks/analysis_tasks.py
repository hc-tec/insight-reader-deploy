# -*- coding: utf-8 -*-
"""
æ–‡ç« æ·±åº¦åˆ†æå¼‚æ­¥ä»»åŠ¡
"""

from app.celery_app import celery_app
from app.services.unified_analysis_service import UnifiedAnalysisService
from app.db.database import get_db
from app.models.models import Article, AnalysisReport
from app.api.sse import notify_analysis_complete, notify_analysis_progress
import asyncio
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


@celery_app.task(bind=True, max_retries=3)
def analyze_article_task(self, article_id: int, user_id: int = None):
    """
    å¼‚æ­¥åˆ†ææ–‡ç« ä»»åŠ¡

    Args:
        self: Celery ä»»åŠ¡å®ä¾‹
        article_id: æ–‡ç«  ID
        user_id: ç”¨æˆ· IDï¼ˆç”¨äºå‘é€ SSE é€šçŸ¥ï¼‰

    Returns:
        åˆ†ææŠ¥å‘Š ID
    """
    logger.info(f"ğŸš€ å¼€å§‹åˆ†ææ–‡ç«  {article_id}...")

    db = next(get_db())

    try:
        # 1. è·å–æ–‡ç« 
        article = db.query(Article).filter(Article.id == article_id).first()
        if not article:
            raise ValueError(f"æ–‡ç« ä¸å­˜åœ¨: {article_id}")

        # 2. åˆ›å»ºæˆ–æ›´æ–°åˆ†ææŠ¥å‘Šè®°å½•
        report = db.query(AnalysisReport).filter(
            AnalysisReport.article_id == article_id
        ).first()

        if not report:
            report = AnalysisReport(
                article_id=article_id,
                status='processing'
            )
            db.add(report)
        else:
            report.status = 'processing'
            report.retry_count += 1

        db.commit()
        logger.info(f"ğŸ“ åˆ†ææŠ¥å‘Šè®°å½•å·²åˆ›å»º/æ›´æ–°ï¼ŒçŠ¶æ€: processing")

        # 3. å‘é€è¿›åº¦é€šçŸ¥ï¼ˆå¦‚æœæœ‰ç”¨æˆ·IDï¼‰
        if user_id:
            asyncio.run(notify_analysis_progress(
                user_id, article_id, "extracting_concepts", 20
            ))

        # 4. è°ƒç”¨ AI åˆ†ææœåŠ¡
        analysis_service = UnifiedAnalysisService()
        result = asyncio.run(analysis_service.analyze_article(
            article.content,
            article.title
        ))

        logger.info(f"âœ… AI åˆ†æå®Œæˆ")

        # 5. å‘é€è¿›åº¦é€šçŸ¥
        if user_id:
            asyncio.run(notify_analysis_progress(
                user_id, article_id, "finalizing", 90
            ))

        # 6. ä¿å­˜åˆ†æç»“æœ
        report.report_data = result['report']
        report.model_used = result['metadata']['model']
        report.tokens_used = result['metadata']['tokens']
        report.processing_time_ms = result['metadata']['processing_time_ms']
        report.status = 'completed'
        report.completed_at = datetime.utcnow()
        report.error_message = None

        db.commit()
        logger.info(f"ğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°æ•°æ®åº“")

        # 7. å‘é€å®Œæˆé€šçŸ¥
        if user_id:
            asyncio.run(notify_analysis_complete(user_id, article_id))
            logger.info(f"ğŸ“¬ å·²é€šçŸ¥ç”¨æˆ· {user_id} åˆ†æå®Œæˆ")

        return report.id

    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")

        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€ä¸ºå¤±è´¥
        if 'report' in locals():
            report.status = 'failed'
            report.error_message = str(e)
            db.commit()

        # é‡è¯•é€»è¾‘
        if self.request.retries < self.max_retries:
            logger.error(f"ğŸ”„ å‡†å¤‡é‡è¯• (ç¬¬ {self.request.retries + 1} æ¬¡)...")
            raise self.retry(exc=e, countdown=60)  # 60ç§’åé‡è¯•
        else:
            logger.error(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»»åŠ¡å¤±è´¥")
            raise

    finally:
        db.close()


@celery_app.task
def batch_analyze_articles(article_ids: list, user_id: int = None):
    """
    æ‰¹é‡åˆ†ææ–‡ç« 

    Args:
        article_ids: æ–‡ç«  ID åˆ—è¡¨
        user_id: ç”¨æˆ· ID

    Returns:
        æˆåŠŸåˆ†æçš„æ–‡ç« æ•°é‡
    """
    logger.info(f"ğŸ“š å¼€å§‹æ‰¹é‡åˆ†æ {len(article_ids)} ç¯‡æ–‡ç« ...")

    success_count = 0
    for article_id in article_ids:
        try:
            analyze_article_task.delay(article_id, user_id)
            success_count += 1
        except Exception as e:
            logger.error(f"âŒ æ–‡ç«  {article_id} åˆ†æä»»åŠ¡åˆ›å»ºå¤±è´¥: {str(e)}")

    logger.info(f"âœ… æ‰¹é‡åˆ†æä»»åŠ¡åˆ›å»ºå®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(article_ids)}")
    return success_count
